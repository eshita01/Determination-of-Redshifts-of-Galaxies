{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinguishing galaxy type using parameters like wavelength , Concentration or Luminosity profile ,eccentricity and colour indices using SDSS and Galaxy Zoo data for 780 Galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def splitdata_train_test(data, fraction_training):\n",
    "  # complete this function\n",
    "  np.random.shuffle(data)\n",
    "  split_index = int(fraction_training*len(data))\n",
    "  return data[:split_index], data[split_index:]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "  # set the fraction of data which should be in the training set\n",
    "  fraction_training = 0.7\n",
    "\n",
    "  # split the data using your function\n",
    "  training, testing = splitdata_train_test(data, fraction_training)\n",
    "\n",
    "  # print the key values\n",
    "  print('Number data galaxies:', len(data))\n",
    "  print('Train fraction:', fraction_training)\n",
    "  print('Number of galaxies in training set:', len(training))\n",
    "  print('Number of galaxies in testing set:', len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number data galaxies: 780\n",
      "Train fraction: 0.7\n",
      "Number of galaxies in training set: 546\n",
      "Number of galaxies in testing set: 234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def splitdata_train_test(data, fraction_training):\n",
    "  # complete this function\n",
    "  np.random.shuffle(data)\n",
    "  split_index = int(fraction_training*len(data))\n",
    "  return data[:split_index], data[split_index:]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "  # set the fraction of data which should be in the training set\n",
    "  fraction_training = 0.7\n",
    "\n",
    "  # split the data using your function\n",
    "  training, testing = splitdata_train_test(data, fraction_training)\n",
    "\n",
    "  # print the key values\n",
    "  print('Number data galaxies:', len(data))\n",
    "  print('Train fraction:', fraction_training)\n",
    "  print('Number of galaxies in training set:', len(training))\n",
    "  print('Number of galaxies in testing set:', len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('galaxy_catalogue.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8576499999999996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['u-g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u-g        1.85765\n",
      "g-r        0.67158\n",
      "r-i        0.4231\n",
      "i-z        0.3061\n",
      "ecc        0.585428\n",
      "m4_u       2.25195\n",
      "m4_g       2.33985\n",
      "m4_r       2.38065\n",
      "m4_i       2.35974\n",
      "m4_z       2.39553\n",
      "petroR50_u 3.09512\n",
      "petroR50_r 3.81892\n",
      "petroR50_z 3.82623\n",
      "petroR90_u 5.17481\n",
      "petroR90_r 8.26301\n",
      "petroR90_z 11.4773\n",
      "class      merger\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load('galaxy_catalogue.npy')\n",
    "for name, value in zip(data.dtype.names, data[0]):\n",
    "  print('{:10} {:.6}'.format(name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some initial results...\n",
      "   predicted,  actual\n",
      "0. merger, merger\n",
      "1. merger, merger\n",
      "2. elliptical, elliptical\n",
      "3. elliptical, elliptical\n",
      "4. spiral, spiral\n",
      "5. merger, spiral\n",
      "6. merger, spiral\n",
      "7. merger, spiral\n",
      "8. merger, merger\n",
      "9. merger, merger\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def splitdata_train_test(data, fraction_training):\n",
    "  np.random.seed(0)\n",
    "  np.random.shuffle(data)\n",
    "  split = int(len(data) * fraction_training)\n",
    "  training_set = data[:split]\n",
    "  testing_set = data[split :]\n",
    "  return (training_set, testing_set)\n",
    "\n",
    "def generate_features_targets(data):\n",
    "  targets = data['class']\n",
    "  features = np.empty(shape=(len(data), 13))\n",
    "  features[:, 0] = data['u-g']\n",
    "  features[:, 1] = data['g-r']\n",
    "  features[:, 2] = data['r-i']\n",
    "  features[:, 3] = data['i-z']\n",
    "  features[:, 4] = data['ecc']\n",
    "  features[:, 5] = data['m4_u']\n",
    "  features[:, 6] = data['m4_g']\n",
    "  features[:, 7] = data['m4_r']\n",
    "  features[:, 8] = data['m4_i']\n",
    "  features[:, 9] = data['m4_z']\n",
    "  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n",
    "  features[:, 11] = data['petroR50_r']/data['petroR90_r']\n",
    "  features[:, 12] = data['petroR50_z']/data['petroR90_z']\n",
    "  return features, targets\n",
    "\n",
    "def dtc_predict_actual(data):\n",
    "  training, testing = splitdata_train_test(data, 0.7)\n",
    "  train_features, train_targets = generate_features_targets(training)\n",
    "  test_features, test_targets = generate_features_targets(testing)\n",
    "  dtc = DecisionTreeClassifier()\n",
    "  dtc.fit(train_features, train_targets)\n",
    "  predictions = dtc.predict(test_features)\n",
    "  return (predictions, test_targets)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "    \n",
    "  predicted_class, actual_class = dtc_predict_actual(data)\n",
    "\n",
    "  # Print some of the initial results\n",
    "  print(\"Some initial results...\\n   predicted,  actual\")\n",
    "  for i in range(10):\n",
    "    print(\"{}. {}, {}\".format(i, predicted_class[i], actual_class[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.60844,  2.06669,  1.31461,  2.45772,  2.07598,  2.00626,\n",
       "        1.73236,  1.80222,  0.86042,  1.14089,  1.47878,  1.86932,\n",
       "        1.18627,  1.28853,  1.82892,  1.47451,  1.98442,  1.90255,\n",
       "        1.6811 ,  1.90579,  1.79695,  1.54299,  1.74904,  1.62334,\n",
       "        1.39331,  1.25031,  1.33324,  1.53427,  1.4784 ,  1.47586,\n",
       "        1.90809,  1.99258,  1.42343,  1.58242,  1.90908,  1.94417,\n",
       "        1.84256,  2.03694,  1.14477,  0.80427,  2.17441,  1.18423,\n",
       "        1.9575 ,  1.39701,  1.86894,  1.56721,  1.21249,  1.94646,\n",
       "        2.03924,  0.90043,  1.91867,  1.9332 ,  1.92719,  1.29274,\n",
       "        1.9629 ,  1.82734,  2.00618,  0.79974,  1.32727,  2.13106,\n",
       "        1.74259,  1.94469,  2.06552,  1.36398,  1.4062 ,  1.78496,\n",
       "        1.91514,  1.94276,  1.8527 ,  1.84882,  1.83376,  1.03384,\n",
       "        1.46197,  2.00159,  1.56972,  1.20485,  1.21816,  1.4801 ,\n",
       "        1.56782,  1.81673,  1.76537,  1.49219,  1.3145 ,  1.54275,\n",
       "        1.30116,  1.78573,  1.41733,  1.4721 ,  1.55892,  2.0231 ,\n",
       "        1.92376,  1.78978,  1.7857 ,  1.90426,  1.4647 ,  2.22675,\n",
       "        2.02511,  1.89801,  1.93194,  1.43569,  1.34058,  1.78559,\n",
       "        1.22154,  1.77547,  1.73257,  2.38323,  2.26917,  1.28303,\n",
       "        1.8926 ,  1.27076,  1.42726,  1.22819,  1.79584,  1.9114 ,\n",
       "        7.38713,  2.10697,  1.34484,  1.58693,  1.77886,  1.98449,\n",
       "        1.98308,  1.23865,  1.29532,  1.8184 ,  1.79767,  1.08861,\n",
       "        1.90854,  1.82565,  1.38634,  1.52052,  1.25116,  1.6847 ,\n",
       "        1.8082 ,  1.98381,  1.56774,  1.74008,  1.54797,  1.74747,\n",
       "        1.16761,  1.25537,  2.50198,  1.28219,  1.12729,  1.38582,\n",
       "        1.97454,  2.00613,  1.50089,  1.33866,  2.42249,  2.05902,\n",
       "        1.11155,  1.01413,  1.97849,  1.63687,  2.0444 ,  1.84064,\n",
       "        1.03696,  2.02685,  2.01632,  2.04526,  1.0403 ,  1.18828,\n",
       "        1.46126,  1.44921,  1.62737,  0.94571,  1.85318,  1.67667,\n",
       "        1.65737,  1.42986,  1.50735,  1.57243,  1.92426,  2.03857,\n",
       "        1.18956,  1.09237,  1.45303,  1.71916,  1.86   ,  1.02941,\n",
       "        1.76654,  1.87057,  1.73717,  1.21524,  1.86495,  1.66139,\n",
       "        1.60453,  1.34441,  1.6703 ,  1.34453,  1.96286,  0.02301,\n",
       "        1.97439,  1.27516,  1.91042,  1.27011,  1.80617,  1.33293,\n",
       "        1.78464,  1.92536,  1.85721,  1.57108,  2.20299,  1.95682,\n",
       "        1.49346,  1.8814 ,  1.81031,  1.52399,  2.04052,  1.19326,\n",
       "        1.95123,  1.99172,  1.90134,  1.37013,  1.75672,  2.0925 ,\n",
       "        1.81417,  2.00458,  1.26268,  1.43684,  1.26703,  2.0835 ,\n",
       "        1.17656,  1.19032,  1.78945,  1.98128,  1.40619,  2.48337,\n",
       "        1.89735,  1.12434,  1.92964,  1.33597,  1.32679,  2.21498,\n",
       "        0.94621,  1.63865,  2.10031,  1.87868,  1.86876,  2.07086,\n",
       "        1.66392,  1.19334,  1.9508 ,  1.19482,  1.98716,  1.83747,\n",
       "        1.35016,  1.35687,  1.89846,  1.86139,  1.48009,  1.85873,\n",
       "        0.93303,  1.30759,  0.7531 ,  1.76539,  1.98872,  1.89362,\n",
       "        0.91376,  2.06313,  1.49681,  1.68791,  1.90766,  1.31969,\n",
       "        1.99217,  1.94457,  1.87671,  1.81796,  0.88745,  1.96175,\n",
       "        1.76423,  1.59309,  1.36383,  1.33324,  1.46496,  0.35784,\n",
       "        1.81007,  2.35909,  1.93282,  1.81913,  1.87699,  1.95815,\n",
       "        1.92493,  1.0819 ,  0.94014,  1.8614 ,  1.62905,  1.75415,\n",
       "        1.67357,  0.79295,  1.69896,  1.08747,  2.15113,  1.22784,\n",
       "        1.2351 ,  1.96622,  0.79506,  1.91798,  1.12185,  0.90785,\n",
       "        1.25935,  0.7305 ,  1.60443,  1.14016,  1.3    ,  1.68245,\n",
       "        2.1222 ,  1.1361 ,  1.94874,  1.887  ,  2.04892,  1.83243,\n",
       "        0.72648,  1.85765,  1.91121,  1.42913,  1.72345,  1.83564,\n",
       "        1.09891,  1.88818,  2.1327 ,  1.71325,  1.8246 ,  1.79745,\n",
       "        1.07673,  0.98065,  2.02032,  0.9747 ,  2.00844,  1.3767 ,\n",
       "        1.83836,  1.66242,  1.19535,  1.90947,  1.41797,  1.8654 ,\n",
       "        1.52396,  1.55862,  1.21518,  1.43902,  1.75892,  1.27061,\n",
       "        2.03065,  1.2284 ,  1.50347,  1.87654,  1.55759,  1.39807,\n",
       "        1.59527,  1.95584,  1.66153,  1.68884,  1.11106,  1.34676,\n",
       "        2.18177,  1.83001,  1.78528,  1.22236,  1.90945,  1.6546 ,\n",
       "        1.77378,  1.3512 ,  1.43393,  1.54834,  1.60272,  2.07089,\n",
       "        2.07372,  1.86286,  1.51248,  2.03469,  1.83027,  1.72804,\n",
       "        1.49954, -8.20235,  1.83167,  1.50247,  0.61117,  1.9694 ,\n",
       "        1.369  ,  1.4342 ,  1.09963,  1.99932,  2.06524,  1.43743,\n",
       "        1.57596,  1.51422,  2.05876,  1.23859,  1.98713,  1.71728,\n",
       "        1.27782,  1.80926,  1.33645,  2.24056,  1.75012,  1.91373,\n",
       "        1.83877,  1.56732,  2.00873,  1.43007,  1.07199,  1.89244,\n",
       "        1.10091,  1.2999 ,  1.15531,  1.38405,  1.4781 ,  2.02957,\n",
       "        0.75462,  1.39194,  1.98402,  1.3411 ,  1.84182,  1.02912,\n",
       "        1.88824,  1.33075,  1.89405,  1.91567,  1.91886,  1.66374,\n",
       "        1.26092,  2.27354,  0.61567,  1.00508,  1.88796,  1.76528,\n",
       "        2.07745,  1.47833,  0.8182 ,  1.06466,  0.82663,  1.94499,\n",
       "        1.11474,  1.90077,  1.94845,  1.44457,  1.12138,  1.92673,\n",
       "        1.85067,  1.28871,  1.9941 ,  2.05906,  1.89824,  1.92156,\n",
       "        2.04655,  1.47216,  1.24929,  0.83962,  1.29919,  1.96382,\n",
       "        1.98007,  1.92203,  2.0718 ,  1.7559 ,  1.81887,  1.99338,\n",
       "        1.95177,  1.22697,  2.05799,  8.14432,  1.80792,  1.12331,\n",
       "        1.99749,  1.50045,  2.01277,  1.14998,  2.03214,  1.96302,\n",
       "        1.51834,  1.93141,  1.68773,  1.52953,  2.24333,  1.24705,\n",
       "        1.86828,  1.06022,  1.91166,  1.88679,  1.83838,  1.82052,\n",
       "        1.98799,  1.78033,  1.06961,  1.83001,  1.89326,  2.45508,\n",
       "        1.37799,  1.94378,  1.94641,  2.00257,  1.51923,  1.28209,\n",
       "        1.34594,  2.11543,  1.95316,  1.92181,  1.35244,  1.10331,\n",
       "        1.6669 ,  1.28115,  1.88835,  1.89639,  1.70176,  1.37095,\n",
       "        1.92182,  1.0308 ,  1.21336,  1.48298,  1.27696,  1.19418,\n",
       "        1.74477,  1.10829,  1.61159,  1.74526,  0.95174,  1.36583,\n",
       "        1.85352,  1.69896,  2.04309,  1.29072,  1.87136,  1.40802,\n",
       "        1.75222,  1.98865,  1.87933,  1.33914,  1.38869,  1.96559,\n",
       "        1.54313,  1.14431,  1.2925 ,  1.90571,  2.10631,  1.83303,\n",
       "        1.93122,  1.98389,  1.95287,  1.7775 ,  1.21451,  0.9989 ,\n",
       "        1.91582,  1.79945,  0.74382,  1.70577,  1.21489,  1.20532,\n",
       "        0.8219 ,  2.03565,  1.83154,  1.88362,  1.50909,  1.43071,\n",
       "        0.80317,  1.03433,  1.19915,  2.15394,  1.9999 ,  1.19789,\n",
       "        1.27016,  1.28507,  1.92302,  0.99846,  1.14767,  1.20197,\n",
       "        1.94076,  1.85441,  1.9675 ,  1.86829,  1.90822,  1.19279,\n",
       "        0.91461,  1.89035,  1.57755,  1.94026,  1.40129,  1.66461,\n",
       "        2.21393,  1.27895,  1.59247,  1.41432,  1.48774,  1.23337,\n",
       "        2.1606 ,  1.34961,  1.58796,  1.99349,  0.98532,  1.09764,\n",
       "        1.50639,  1.23549,  1.0988 ,  1.6492 ,  1.70257,  1.51231,\n",
       "        1.45293,  2.09028,  1.70715,  1.63954,  2.00543,  1.03851,\n",
       "        1.08424,  1.07672,  2.01043,  1.87027,  2.01071,  1.37545,\n",
       "        1.28257,  1.46475,  1.1751 ,  1.78642,  2.10321,  1.97871,\n",
       "        1.41757,  2.01943,  2.0878 ,  1.23617,  2.30115,  2.2761 ,\n",
       "        2.02151,  2.20417,  1.89587,  1.41489,  1.42402,  1.37443,\n",
       "        1.43456,  1.86405,  1.32747,  1.78951,  1.98566,  1.90437,\n",
       "        0.11973,  1.84545,  1.85029,  1.97591,  1.01983,  1.90461,\n",
       "        1.83524,  1.88667,  1.74024,  1.71614,  1.94122,  1.96249,\n",
       "        1.19107,  1.97233,  1.79584,  1.71317,  1.68202,  1.8745 ,\n",
       "        1.87795,  1.90407,  1.43646,  1.70491,  2.03435,  1.37781,\n",
       "        1.35435,  1.47854,  1.50552,  2.1738 ,  1.29427,  1.16865,\n",
       "        0.95559,  1.30626,  1.80996,  1.75722,  2.02283,  1.27881,\n",
       "        1.09544,  1.90182,  1.72037,  2.07173,  1.33059,  1.33915,\n",
       "        1.96083,  1.60342,  1.64601,  1.23976,  1.32195,  1.81798,\n",
       "        1.907  ,  2.00497,  1.97143,  1.95341,  1.19652,  1.70074,\n",
       "        1.92095,  1.9768 ,  2.05078,  1.70175,  1.52795,  1.93809,\n",
       "        1.20084,  1.79702,  1.41472,  1.13595,  1.88901,  1.48522,\n",
       "        1.87731,  2.14023,  1.33313,  1.592  ,  1.63163,  1.41076,\n",
       "        0.80505,  1.69679,  1.85907,  1.29224,  1.74374, 10.62404,\n",
       "        1.55474,  1.4211 ,  1.89739,  1.93962,  1.04851,  1.87883,\n",
       "        1.76278,  2.03973,  0.93995,  1.93274,  1.02191,  1.24234,\n",
       "        1.80439,  1.11682,  1.54704,  2.00112,  1.95561,  2.05588,\n",
       "        1.92857,  1.47296,  1.63321,  1.8884 ,  1.90761,  0.87355,\n",
       "        1.33373,  1.8943 ,  1.93804,  1.67313,  1.60719,  1.80592,\n",
       "        1.34927,  1.01725,  1.25759,  1.2811 ,  1.28056,  1.89898,\n",
       "        1.88772,  2.22236,  1.74404,  1.6945 ,  1.35808,  1.59638,\n",
       "        1.85043,  1.79424,  1.40057,  1.22533,  1.30572,  0.83713,\n",
       "        1.36891,  1.2942 ,  2.25665,  1.43962,  1.35421,  1.89581,\n",
       "        1.52749,  1.85613,  1.81948,  0.99552,  1.94813,  1.94496,\n",
       "        1.22676,  1.58228,  1.86188,  1.64882,  1.7118 ,  2.12809,\n",
       "        1.9054 ,  1.70744,  1.64399,  1.33247,  1.29524,  1.28582])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['u-g']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number data galaxies: 780\n",
      "Train fraction: 0.7\n",
      "Number of galaxies in training set: 546\n",
      "Number of galaxies in testing set: 234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def splitdata_train_test(data, fraction_training):\n",
    "  # complete this function\n",
    "  np.random.shuffle(data)\n",
    "  split_index = int(fraction_training*len(data))\n",
    "  return data[:split_index], data[split_index:]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "  # set the fraction of data which should be in the training set\n",
    "  fraction_training = 0.7\n",
    "\n",
    "  # split the data using your function\n",
    "  training, testing = splitdata_train_test(data, fraction_training)\n",
    "\n",
    "  # print the key values\n",
    "  print('Number data galaxies:', len(data))\n",
    "  print('Train fraction:', fraction_training)\n",
    "  print('Number of galaxies in training set:', len(training))\n",
    "  print('Number of galaxies in testing set:', len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some initial results...\n",
      "   predicted,  actual\n",
      "0. merger, merger\n",
      "1. merger, merger\n",
      "2. elliptical, elliptical\n",
      "3. elliptical, elliptical\n",
      "4. spiral, spiral\n",
      "5. merger, spiral\n",
      "6. merger, spiral\n",
      "7. merger, spiral\n",
      "8. merger, merger\n",
      "9. merger, merger\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# copy your splitdata_train_test function here\n",
    "def splitdata_train_test(data, fraction_training):\n",
    "  np.random.seed(0)\n",
    "  np.random.shuffle(data)  \n",
    "  split = int(len(data)*fraction_training)\n",
    "  return data[:split], data[split:]\n",
    "\n",
    "# copy your generate_features_targets function here\n",
    "def generate_features_targets(data):\n",
    "  # complete the function by calculating the concentrations\n",
    "\n",
    "  targets = data['class']\n",
    "\n",
    "  features = np.empty(shape=(len(data), 13))\n",
    "  features[:, 0] = data['u-g'] + 1\n",
    "  features[:, 1] = data['g-r']\n",
    "  features[:, 2] = data['r-i']\n",
    "  features[:, 3] = data['i-z']\n",
    "  features[:, 4] = data['ecc']\n",
    "  features[:, 5] = data['m4_u']\n",
    "  features[:, 6] = data['m4_g']\n",
    "  features[:, 7] = data['m4_r']\n",
    "  features[:, 8] = data['m4_i']\n",
    "  features[:, 9] = data['m4_z']\n",
    "\n",
    "  # fill the remaining 3 columns with concentrations in the u, r and z filters\n",
    "  # concentration in u filter\n",
    "  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n",
    "  # concentration in r filter\n",
    "  features[:, 11] = data['petroR50_r']/data['petroR90_r']\n",
    "  # concentration in z filter\n",
    "  features[:, 12] = data['petroR50_z']/data['petroR90_z']\n",
    "\n",
    "  return features, targets\n",
    "\n",
    "\n",
    "# complete this function by splitting the data set and training a decision tree classifier\n",
    "def dtc_predict_actual(data):\n",
    "  # split the data into training and testing sets using a training fraction of 0.7\n",
    "  train, test = splitdata_train_test(data, 0.7)\n",
    "\n",
    "  # generate the feature and targets for the training and test sets\n",
    "  # i.e. train_features, train_targets, test_features, test_targets\n",
    "  train_features, train_targets = generate_features_targets(train)\n",
    "  test_features, test_targets = generate_features_targets(test)\n",
    "\n",
    "  # instantiate a decision tree classifier\n",
    "  dtc = DecisionTreeClassifier()\n",
    "\n",
    "  # train the classifier with the train_features and train_targets\n",
    "  dtc.fit(train_features, train_targets)\n",
    "\n",
    "  # get predictions for the test_features\n",
    "  predictions = dtc.predict(test_features)\n",
    "\n",
    "  # return the predictions and the test_targets\n",
    "  return predictions, test_targets\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "    \n",
    "  predicted_class, actual_class = dtc_predict_actual(data)\n",
    "\n",
    "  # Print some of the initial results\n",
    "  print(\"Some initial results...\\n   predicted,  actual\")\n",
    "  for i in range(10):\n",
    "    print(\"{}. {}, {}\".format(i, predicted_class[i], actual_class[i]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def splitdata_train_test(data, fraction_training):\n",
    "  np.random.seed(0)\n",
    "  np.random.shuffle(data)\n",
    "  split = int(len(data) * fraction_training)\n",
    "  training_set = data[:split]\n",
    "  testing_set = data[split :]\n",
    "  return (training_set, testing_set)\n",
    "\n",
    "def generate_features_targets(data):\n",
    "  targets = data['class']\n",
    "  features = np.empty(shape=(len(data), 13))\n",
    "  features[:, 0] = data['u-g']\n",
    "  features[:, 1] = data['g-r']\n",
    "  features[:, 2] = data['r-i']\n",
    "  features[:, 3] = data['i-z']\n",
    "  features[:, 4] = data['ecc']\n",
    "  features[:, 5] = data['m4_u']\n",
    "  features[:, 6] = data['m4_g']\n",
    "  features[:, 7] = data['m4_r']\n",
    "  features[:, 8] = data['m4_i']\n",
    "  features[:, 9] = data['m4_z']\n",
    "  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n",
    "  features[:, 11] = data['petroR50_r']/data['petroR90_r']\n",
    "  features[:, 12] = data['petroR50_z']/data['petroR90_z']\n",
    "  return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some initial results...\n",
      "   predicted,  actual\n",
      "0. merger, merger\n",
      "1. merger, merger\n",
      "2. elliptical, elliptical\n",
      "3. elliptical, elliptical\n",
      "4. spiral, spiral\n",
      "5. merger, spiral\n",
      "6. merger, spiral\n",
      "7. merger, spiral\n",
      "8. merger, merger\n",
      "9. merger, merger\n"
     ]
    }
   ],
   "source": [
    "def dtc_predict_actual(data):\n",
    "  training, testing = splitdata_train_test(data, 0.7)\n",
    "  train_features, train_targets = generate_features_targets(training)\n",
    "  test_features, test_targets = generate_features_targets(testing)\n",
    "  dtc = DecisionTreeClassifier()\n",
    "  dtc.fit(train_features, train_targets)\n",
    "  predictions = dtc.predict(test_features)\n",
    "  return (predictions, test_targets)\n",
    "if __name__ == '__main__':\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "    \n",
    "  predicted_class, actual_class = dtc_predict_actual(data)\n",
    "\n",
    "  # Print some of the initial results\n",
    "  print(\"Some initial results...\\n   predicted,  actual\")\n",
    "  for i in range(10):\n",
    "    print(\"{}. {}, {}\".format(i, predicted_class[i], actual_class[i]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (780, 13)\n",
      "Targets shape: (780,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_features_targets(data):\n",
    "  targets = data['class']\n",
    "  features = np.empty(shape=(len(data), 13))\n",
    "  features[:, 0] = data['u-g']\n",
    "  features[:, 1] = data['g-r']\n",
    "  features[:, 2] = data['r-i']\n",
    "  features[:, 3] = data['i-z']\n",
    "  features[:, 4] = data['ecc']\n",
    "  features[:, 5] = data['m4_u']\n",
    "  features[:, 6] = data['m4_g']\n",
    "  features[:, 7] = data['m4_r']\n",
    "  features[:, 8] = data['m4_i']\n",
    "  features[:, 9] = data['m4_z']\n",
    "  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n",
    "  features[:, 11] = data['petroR50_r']/data['petroR90_r']\n",
    "  features[:, 12] = data['petroR50_z']/data['petroR90_z']\n",
    "  return features, targets\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "  features, targets = generate_features_targets(data)\n",
    "\n",
    "  # Print the shape of each array to check the arrays are the correct dimensions. \n",
    "  print(\"Features shape:\", features.shape)\n",
    "  print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some initial results...\n",
      "   predicted,  actual\n",
      "0. merger, merger\n",
      "1. merger, merger\n",
      "2. elliptical, elliptical\n",
      "3. elliptical, elliptical\n",
      "4. spiral, spiral\n",
      "5. merger, spiral\n",
      "6. merger, spiral\n",
      "7. merger, spiral\n",
      "8. merger, merger\n",
      "9. merger, merger\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# copy your splitdata_train_test function here\n",
    "def splitdata_train_test(data, fraction_training):\n",
    "  np.random.seed(0)\n",
    "  np.random.shuffle(data)  \n",
    "  split = int(len(data)*fraction_training)\n",
    "  return data[:split], data[split:]\n",
    "\n",
    "# copy your generate_features_targets function here\n",
    "def generate_features_targets(data):\n",
    "  # complete the function by calculating the concentrations\n",
    "\n",
    "  targets = data['class']\n",
    "\n",
    "  features = np.empty(shape=(len(data), 13))\n",
    "  features[:, 0] = data['u-g'] + 1\n",
    "  features[:, 1] = data['g-r']\n",
    "  features[:, 2] = data['r-i']\n",
    "  features[:, 3] = data['i-z']\n",
    "  features[:, 4] = data['ecc']\n",
    "  features[:, 5] = data['m4_u']\n",
    "  features[:, 6] = data['m4_g']\n",
    "  features[:, 7] = data['m4_r']\n",
    "  features[:, 8] = data['m4_i']\n",
    "  features[:, 9] = data['m4_z']\n",
    "\n",
    "  # fill the remaining 3 columns with concentrations in the u, r and z filters\n",
    "  # concentration in u filter\n",
    "  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n",
    "  # concentration in r filter\n",
    "  features[:, 11] = data['petroR50_r']/data['petroR90_r']\n",
    "  # concentration in z filter\n",
    "  features[:, 12] = data['petroR50_z']/data['petroR90_z']\n",
    "\n",
    "  return features, targets\n",
    "\n",
    "\n",
    "# complete this function by splitting the data set and training a decision tree classifier\n",
    "def dtc_predict_actual(data):\n",
    "  # split the data into training and testing sets using a training fraction of 0.7\n",
    "  train, test = splitdata_train_test(data, 0.7)\n",
    "\n",
    "  # generate the feature and targets for the training and test sets\n",
    "  # i.e. train_features, train_targets, test_features, test_targets\n",
    "  train_features, train_targets = generate_features_targets(train)\n",
    "  test_features, test_targets = generate_features_targets(test)\n",
    "\n",
    "  # instantiate a decision tree classifier\n",
    "  dtc = DecisionTreeClassifier()\n",
    "\n",
    "  # train the classifier with the train_features and train_targets\n",
    "  dtc.fit(train_features, train_targets)\n",
    "\n",
    "  # get predictions for the test_features\n",
    "  predictions = dtc.predict(test_features)\n",
    "\n",
    "  # return the predictions and the test_targets\n",
    "  return predictions, test_targets\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "    \n",
    "  predicted_class, actual_class = dtc_predict_actual(data)\n",
    "\n",
    "  # Print some of the initial results\n",
    "  print(\"Some initial results...\\n   predicted,  actual\")\n",
    "  for i in range(10):\n",
    "    print(\"{}. {}, {}\".format(i, predicted_class[i], actual_class[i]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and model score FURTHERMORE improoving the accuracy using randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8615384615384616\n",
      "Confusion matrix, without normalization\n",
      "[[245  14   1]\n",
      " [ 14 210  36]\n",
      " [  4  39 217]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from support_functions import generate_features_targets, plot_confusion_matrix, calculate_accuracy\n",
    "\n",
    "def calculate_accuracy(predicted_classes, actual_classes, ):\n",
    "    return sum(actual_classes[:] == predicted_classes[:]) / len(actual_classes)\n",
    "\n",
    "\n",
    "def generate_features_targets(data):\n",
    "    output_targets = np.empty(shape=(len(data)), dtype='<U20')\n",
    "    output_targets[:] = data['class']\n",
    "\n",
    "    input_features = np.empty(shape=(len(data), 13))\n",
    "    input_features[:, 0] = data['u-g']\n",
    "    input_features[:, 1] = data['g-r']\n",
    "    input_features[:, 2] = data['r-i']\n",
    "    input_features[:, 3] = data['i-z']\n",
    "    input_features[:, 4] = data['ecc']\n",
    "    input_features[:, 5] = data['m4_u']\n",
    "    input_features[:, 6] = data['m4_g']\n",
    "    input_features[:, 7] = data['m4_r']\n",
    "    input_features[:, 8] = data['m4_i']\n",
    "    input_features[:, 9] = data['m4_z']\n",
    "    input_features[:, 10] = data['petroR50_u'] / data['petroR90_u']\n",
    "    input_features[:, 11] = data['petroR50_r'] / data['petroR90_r']\n",
    "    input_features[:, 12] = data['petroR50_z'] / data['petroR90_z']\n",
    "\n",
    "    return input_features, output_targets\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "\n",
    "\n",
    "def rf_predict_actual(data, n_estimators):\n",
    "  features, targets = generate_features_targets(data)\n",
    "  rfc = RandomForestClassifier(n_estimators=n_estimators)\n",
    "  predictions = cross_val_predict(rfc, features, targets, cv=10)\n",
    "  return (predictions, data['class'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "  # get the predicted and actual classes\n",
    "  number_estimators = 50              # Number of trees\n",
    "  predicted, actual = rf_predict_actual(data, number_estimators)\n",
    "\n",
    "  # calculate the model score using your function\n",
    "  accuracy = calculate_accuracy(predicted, actual)\n",
    "  print(\"Accuracy score:\", accuracy)\n",
    "\n",
    "  # calculate the models confusion matrix using sklearns confusion_matrix function\n",
    "  class_labels = list(set(actual))\n",
    "  model_cm = confusion_matrix(y_true=actual, y_pred=predicted, labels=class_labels)\n",
    "\n",
    "  # plot the confusion matrix using the provided functions.\n",
    "  plt.figure()\n",
    "  plot_confusion_matrix(model_cm, classes=class_labels, normalize=False)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
